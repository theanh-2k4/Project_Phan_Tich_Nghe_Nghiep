{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018b066f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches:  30%|███       | 32/105 [15:54<36:59, 30.41s/it]"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from bertopic import BERTopic\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from umap import UMAP\n",
    "from hdbscan import HDBSCAN\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# 1. Load data\n",
    "df = pd.read_csv(r\"../Datasets/jobs_cleaned.csv\")\n",
    "docs = df['e5_input'].tolist()\n",
    "classes = df['Chuyên môn'].tolist() # DA, DS, MLE\n",
    "\n",
    "# 2. Embedding với E5 (Dùng bản multilingual cho Anh-Việt)\n",
    "embedding_model = SentenceTransformer('intfloat/multilingual-e5-large')\n",
    "embeddings = embedding_model.encode(docs, show_progress_bar=True)\n",
    "\n",
    "# 3. Cấu hình các thành phần (Fix lỗi ensure_all_finite bằng cách khởi tạo mới)\n",
    "umap_model = UMAP(n_neighbors=15, n_components=5, min_dist=0.0, metric='cosine', random_state=42)\n",
    "hdbscan_model = HDBSCAN(min_cluster_size=10, metric='euclidean', cluster_selection_method='eom', prediction_data=True)\n",
    "vectorizer_model = CountVectorizer(stop_words=\"english\", min_df=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7eb4c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lưu models để sử dụng lại sau này\n",
    "embedding_model.save(r\"../Models/embedding_model\")\n",
    "umap_model.save(r\"../Models/umap_model\")\n",
    "hdbscan_model.save(r\"../Models/hdbscan_model\")\n",
    "vectorizer_model.save(r\"../Models/vectorizer_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1afd48da",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "check_array() got an unexpected keyword argument 'ensure_all_finite'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\thean\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\bertopic\\_bertopic.py:3794\u001b[39m, in \u001b[36mBERTopic._reduce_dimensionality\u001b[39m\u001b[34m(self, embeddings, y, partial_fit)\u001b[39m\n\u001b[32m   3793\u001b[39m     y = np.array(y) \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m3794\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mumap_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m=\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3795\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\thean\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\umap\\umap_.py:2372\u001b[39m, in \u001b[36mUMAP.fit\u001b[39m\u001b[34m(self, X, y, ensure_all_finite, **kwargs)\u001b[39m\n\u001b[32m   2371\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2372\u001b[39m     X = \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2373\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2374\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfloat32\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2375\u001b[39m \u001b[43m        \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcsr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   2376\u001b[39m \u001b[43m        \u001b[49m\u001b[43morder\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mC\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   2377\u001b[39m \u001b[43m        \u001b[49m\u001b[43mensure_all_finite\u001b[49m\u001b[43m=\u001b[49m\u001b[43mensure_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2378\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2379\u001b[39m \u001b[38;5;28mself\u001b[39m._raw_data = X\n",
      "\u001b[31mTypeError\u001b[39m: check_array() got an unexpected keyword argument 'ensure_all_finite'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# 4. Train model\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m topics, probs = \u001b[43mtopic_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdocs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# 5. Phân tích Topic theo Chuyên môn (DA, DS, MLE)\u001b[39;00m\n\u001b[32m      5\u001b[39m topics_per_class = topic_model.topics_per_class(docs, classes=categories)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\thean\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\bertopic\\_bertopic.py:472\u001b[39m, in \u001b[36mBERTopic.fit_transform\u001b[39m\u001b[34m(self, documents, embeddings, images, y)\u001b[39m\n\u001b[32m    469\u001b[39m     y, embeddings = \u001b[38;5;28mself\u001b[39m._guided_topic_modeling(embeddings)\n\u001b[32m    471\u001b[39m \u001b[38;5;66;03m# Reduce dimensionality and fit UMAP model\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m472\u001b[39m umap_embeddings = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_reduce_dimensionality\u001b[49m\u001b[43m(\u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    474\u001b[39m \u001b[38;5;66;03m# Zero-shot Topic Modeling\u001b[39;00m\n\u001b[32m    475\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._is_zeroshot():\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\thean\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\bertopic\\_bertopic.py:3796\u001b[39m, in \u001b[36mBERTopic._reduce_dimensionality\u001b[39m\u001b[34m(self, embeddings, y, partial_fit)\u001b[39m\n\u001b[32m   3794\u001b[39m         \u001b[38;5;28mself\u001b[39m.umap_model.fit(embeddings, y=y)\n\u001b[32m   3795\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3796\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mumap_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3798\u001b[39m umap_embeddings = \u001b[38;5;28mself\u001b[39m.umap_model.transform(embeddings)\n\u001b[32m   3799\u001b[39m logger.info(\u001b[33m\"\u001b[39m\u001b[33mDimensionality - Completed \u001b[39m\u001b[38;5;130;01m\\u2713\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\thean\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\umap\\umap_.py:2372\u001b[39m, in \u001b[36mUMAP.fit\u001b[39m\u001b[34m(self, X, y, ensure_all_finite, **kwargs)\u001b[39m\n\u001b[32m   2368\u001b[39m     X = check_array(\n\u001b[32m   2369\u001b[39m         X, dtype=np.uint8, order=\u001b[33m\"\u001b[39m\u001b[33mC\u001b[39m\u001b[33m\"\u001b[39m, ensure_all_finite=ensure_all_finite\n\u001b[32m   2370\u001b[39m     )\n\u001b[32m   2371\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2372\u001b[39m     X = \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2373\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2374\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfloat32\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2375\u001b[39m \u001b[43m        \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcsr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   2376\u001b[39m \u001b[43m        \u001b[49m\u001b[43morder\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mC\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   2377\u001b[39m \u001b[43m        \u001b[49m\u001b[43mensure_all_finite\u001b[49m\u001b[43m=\u001b[49m\u001b[43mensure_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2378\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2379\u001b[39m \u001b[38;5;28mself\u001b[39m._raw_data = X\n\u001b[32m   2381\u001b[39m \u001b[38;5;66;03m# Handle all the optional arguments, setting default\u001b[39;00m\n",
      "\u001b[31mTypeError\u001b[39m: check_array() got an unexpected keyword argument 'ensure_all_finite'"
     ]
    }
   ],
   "source": [
    "# 4. Khởi tạo và chạy BERTopic\n",
    "topic_model = BERTopic(\n",
    "    embedding_model=embedding_model,\n",
    "    umap_model=umap_model,\n",
    "    hdbscan_model=hdbscan_model,\n",
    "    vectorizer_model=vectorizer_model,\n",
    "    nr_topics=\"auto\"\n",
    ")\n",
    "\n",
    "topics, probs = topic_model.fit_transform(docs, embeddings)\n",
    "\n",
    "# 5. Tính toán phân bổ theo chuyên môn (Để dùng cho đoạn code dưới)\n",
    "topics_per_class = topic_model.topics_per_class(docs, classes=classes)\n",
    "\n",
    "# 6. Trực quan hóa\n",
    "fig_topics = topic_model.visualize_topics()\n",
    "fig_hierarchy = topic_model.visualize_hierarchy()\n",
    "fig_barchart = topic_model.visualize_barchart(top_n_topics=10)\n",
    "fig_class = topic_model.visualize_topics_per_class(topics_per_class)\n",
    "\n",
    "# Lưu kết quả\n",
    "topic_model.save(r\"../Models/job_topic_model\")\n",
    "fig_barchart.write_html(r\"../Figures/topic_keywords.html\")\n",
    "fig_class.write_html(r\"../Figures/topics_by_job_role.html\")\n",
    "\n",
    "print(\" Hoàn thành, xem file topics_by_job_role.html để thấy sự khác biệt giữa 3 ngành.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "842497fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic -1 → không, có, neutral, mà, mua\n",
      "Topic 0 → pro, 15, 16, 14, 13\n",
      "Topic 1 → s23, ultra, s24, s25, s23u\n",
      "Topic 2 → bác, không, đâu, mà, gì\n",
      "Topic 3 → iphone, android, apple, ip, samsung\n",
      "Topic 4 → neutral, tiền, không, có, mà\n",
      "Topic 5 → video, camera, chụp, review, ảnh\n",
      "Topic 6 → may, co, ban, quá, đầu\n",
      "Topic 7 → sạc, pin, nhanh, không, dùng\n",
      "Topic 8 → fold, flip, gập, n3, find\n",
      "Topic 9 → x8, find, oppo, pro, x7\n",
      "Topic 10 → oppo, vivo, hơn, chụp, nó\n",
      "Topic 11 → x200, vivo, mini, pro, x200pro\n",
      "Topic 12 → xiaomi, phần, không, nó, hãng\n",
      "Topic 13 → samsung, sam, sony, sung, samfan\n"
     ]
    }
   ],
   "source": [
    "# 1. Lấy thông tin tổng quan về các topic\n",
    "topic_info = topic_model.get_topic_info()\n",
    "\n",
    "# 2. Lọc top 15 topic (loại bỏ topic -1 vì đó là các tài liệu bị nhiễu/outliers)\n",
    "top_15_topics = topic_info[topic_info[\"Topic\"] != -1].head(15)\n",
    "\n",
    "print(f\"{'ID':<5} | {'Số lượng':<8} | {'Từ khóa đặc trưng (Mô tả)':<60}\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "for topic_id in top_15_topics[\"Topic\"]:\n",
    "    # Lấy các từ khóa và trọng số\n",
    "    words_data = topic_model.get_topic(topic_id)\n",
    "    \n",
    "    if not words_data:\n",
    "        description = \"Không có mô tả\"\n",
    "    else:\n",
    "        # Lấy 7 từ đầu tiên để mô tả rõ hơn về kỹ năng/công cụ\n",
    "        description = \", \".join([word[0] for word in words_data[:7]])\n",
    "    \n",
    "    # Lấy số lượng tài liệu trong topic này\n",
    "    count = topic_info[topic_info[\"Topic\"] == topic_id][\"Count\"].values[0]\n",
    "    \n",
    "    print(f\"{topic_id:<5} | {count:<8} | {description}\")\n",
    "\n",
    "# --- PHẦN BỔ SUNG: Xem topic này thuộc về Chuyên môn nào nhiều nhất ---\n",
    "print(\"\\n\" + \"=\"*30)\n",
    "print(\"PHÂN TÍCH TOPIC THEO CHUYÊN MÔN (DA, DS, MLE)\")\n",
    "print(\"=\"*30)\n",
    "\n",
    "# Trích xuất phân bổ topic theo class (đã tạo ở Step 2)\n",
    "# Dùng để xem top 3 chuyên môn quan tâm đến topic này nhất\n",
    "for topic_id in top_15_topics[\"Topic\"]:\n",
    "    # Lấy tên topic (từ khóa đầu tiên)\n",
    "    topic_label = topic_model.get_topic(topic_id)[0][0]\n",
    "    \n",
    "    # Hiển thị phân bổ (dựa trên bảng topics_per_class đã tính ở bước trước)\n",
    "    relevant_classes = topics_per_class[topics_per_class[\"Topic\"] == topic_id]\n",
    "    relevant_classes = relevant_classes.sort_values(\"Frequency\", ascending=False).head(3)\n",
    "    \n",
    "    dist_str = \" | \".join([f\"{row['Class']}: {row['Frequency']}\" for _, row in relevant_classes.iterrows()])\n",
    "    print(f\"Topic {topic_id} ({topic_label}): {dist_str}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
